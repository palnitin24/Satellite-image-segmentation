{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing & Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keract\n",
      "  Downloading keract-4.5.1-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: keract\n",
      "Successfully installed keract-4.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install keract\n",
    "import keract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from IPython.display import SVG\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os, re, sys, random, shutil, cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, Nadam\n",
    "from tensorflow.keras import applications, optimizers\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.utils import model_to_dot, plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger, LearningRateScheduler\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, ZeroPadding2D, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation using Albumentations Library\n",
    "[Albumentations](https://albumentations.ai/) is a Python library for fast and flexible image augmentations. Albumentations efficiently implements a rich variety of image transform operations that are optimized for performance, and does so while providing a concise, yet powerful image augmentation interface for different computer vision tasks, including object classification, segmentation, and detection.\n",
    "\n",
    "Data augmentation is done by the following techniques:\n",
    "\n",
    "1. Random Cropping\n",
    "2. Horizontal Flipping\n",
    "3. Vertical Flipping\n",
    "4. Rotation\n",
    "5. Random Brightness & Contrast\n",
    "6. Contrast Limited Adaptive Histogram Equalization (CLAHE)\n",
    "7. Grid Distortion\n",
    "8. Optical Distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(width, height):\n",
    "    transform = A.Compose([\n",
    "        A.RandomCrop(width=width, height=height, p=1.0),\n",
    "        A.HorizontalFlip(p=1.0),\n",
    "        A.VerticalFlip(p=1.0),\n",
    "        A.Rotate(limit=[60, 300], p=1.0, interpolation=cv2.INTER_NEAREST),\n",
    "        A.RandomBrightnessContrast(brightness_limit=[-0.2, 0.3], contrast_limit=0.2, p=1.0),\n",
    "        A.OneOf([\n",
    "            A.CLAHE (clip_limit=1.5, tile_grid_size=(8, 8), p=0.5),\n",
    "            A.GridDistortion(p=0.5),\n",
    "            A.OpticalDistortion(distort_limit=1, shift_limit=0.5, interpolation=cv2.INTER_NEAREST, p=0.5),\n",
    "        ], p=1.0),\n",
    "    ], p=1.0)\n",
    "\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(image, mask, original_image=None, original_mask=None):\n",
    "    fontsize = 16\n",
    "\n",
    "    if original_image is None and original_mask is None:\n",
    "        f, ax = plt.subplots(2, 1, figsize=(10, 10), squeeze=True)\n",
    "        f.set_tight_layout(h_pad=5, w_pad=5)\n",
    "\n",
    "        ax[0].imshow(image)\n",
    "        ax[1].imshow(mask)\n",
    "    else:\n",
    "        f, ax = plt.subplots(2, 2, figsize=(16, 12), squeeze=True)\n",
    "        plt.tight_layout(pad=0.2, w_pad=1.0, h_pad=0.01)\n",
    "\n",
    "        ax[0, 0].imshow(original_image)\n",
    "        ax[0, 0].set_title('Original Image', fontsize=fontsize)\n",
    "\n",
    "        ax[1, 0].imshow(original_mask)\n",
    "        ax[1, 0].set_title('Original Mask', fontsize=fontsize)\n",
    "\n",
    "        ax[0, 1].imshow(image)\n",
    "        ax[0, 1].set_title('Transformed Image', fontsize=fontsize)\n",
    "\n",
    "        ax[1, 1].imshow(mask)\n",
    "        ax[1, 1].set_title('Transformed Mask', fontsize=fontsize)\n",
    "\n",
    "    plt.savefig('sample_augmented_image.png', facecolor= 'w', transparent= False, bbox_inches= 'tight', dpi= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Define dataset paths and parameters\n",
    "# dataset_root_folder = '/content/drive/MyDrive/Colab Notebooks/Datasets/satellite/'\n",
    "# dataset_name = \"\"\n",
    "# image = cv2.imread(f'{dataset_root_folder}/{dataset_name}/Tile {tile_id}/{image_type}/image_part_00{image_id}.{image_extension}', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'visualize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[0;32m<ipython-input-5-7900b8b379e6>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m     15\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./mask.png'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m---> 17\u001b[0;31m \u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'visualize' is not defined"
     ]
    }
   ],
   "source": [
    "# image = cv2.imread(\"../input/dubai-aerial-imagery-dataset/train_images/train/image_t8_007.jpg\")\n",
    "image = cv2.imread(\"/content/drive/MyDrive/Colab Notebooks/Datasets/satellite/DubaiDataset/images/image_t8_007.jpg\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# mask = cv2.imread(\"../input/dubai-aerial-imagery-dataset/train_masks/train/image_t8_007.png\")\n",
    "mask = cv2.imread(\"/content/drive/MyDrive/Colab Notebooks/Datasets/satellite/DubaiDataset/masks/image_t8_007.png\")\n",
    "mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "transform = augment(1920, 1280)\n",
    "transformed = transform(image=image, mask=mask)\n",
    "transformed_image = transformed['image']\n",
    "transformed_mask = transformed['mask']\n",
    "\n",
    "cv2.imwrite('./image.png',cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB))\n",
    "cv2.imwrite('./mask.png',cv2.cvtColor(transformed_mask, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "visualize(transformed_image, transformed_mask, image, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Augmented Images to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_dir = '../input/dubai-aerial-imagery-dataset/train_images/train/'\n",
    "# masks_dir = '../input/dubai-aerial-imagery-dataset/train_masks/train/'\n",
    "images_dir = '/content/drive/MyDrive/Colab Notebooks/Datasets/satellite/DubaiDataset/images/'\n",
    "masks_dir = '/content/drive/MyDrive/Colab Notebooks/Datasets/satellite/DubaiDataset/masks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = np.sort(os.listdir(images_dir))\n",
    "file_names = np.char.split(file_names, '.')\n",
    "filenames = np.array([])\n",
    "for i in range(len(file_names)):\n",
    "    filenames = np.append(filenames, file_names[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_dataset(count):\n",
    "    '''Function for data augmentation\n",
    "        Input:\n",
    "            count - total no. of images after augmentation = initial no. of images * count\n",
    "        Output:\n",
    "            writes augmented images (input images & segmentation masks) to the working directory\n",
    "    '''\n",
    "    transform_1 = augment(512, 512)\n",
    "    transform_2 = augment(480, 480)\n",
    "    transform_3 = augment(512, 512)\n",
    "    transform_4 = augment(800, 800)\n",
    "    transform_5 = augment(1024, 1024)\n",
    "    transform_6 = augment(800, 800)\n",
    "    transform_7 = augment(1600, 1600)\n",
    "    transform_8 = augment(1920, 1280)\n",
    "\n",
    "    i = 0\n",
    "    for i in range(count):\n",
    "        for file in filenames:\n",
    "            tile = file.split('_')[1]\n",
    "            img = cv2.imread(images_dir+file+'.jpg')\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            mask = cv2.imread(masks_dir+file+'.png')\n",
    "            mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            if tile == 't1':\n",
    "                transformed = transform_1(image=img, mask=mask)\n",
    "                transformed_image = transformed['image']\n",
    "                transformed_mask = transformed['mask']\n",
    "            elif tile =='t2':\n",
    "                transformed = transform_2(image=img, mask=mask)\n",
    "                transformed_image = transformed['image']\n",
    "                transformed_mask = transformed['mask']\n",
    "            elif tile =='t3':\n",
    "                transformed = transform_3(image=img, mask=mask)\n",
    "                transformed_image = transformed['image']\n",
    "                transformed_mask = transformed['mask']\n",
    "            elif tile =='t4':\n",
    "                transformed = transform_4(image=img, mask=mask)\n",
    "                transformed_image = transformed['image']\n",
    "                transformed_mask = transformed['mask']\n",
    "            elif tile =='t5':\n",
    "                transformed = transform_5(image=img, mask=mask)\n",
    "                transformed_image = transformed['image']\n",
    "                transformed_mask = transformed['mask']\n",
    "            elif tile =='t6':\n",
    "                transformed = transform_6(image=img, mask=mask)\n",
    "                transformed_image = transformed['image']\n",
    "                transformed_mask = transformed['mask']\n",
    "            elif tile =='t7':\n",
    "                transformed = transform_7(image=img, mask=mask)\n",
    "                transformed_image = transformed['image']\n",
    "                transformed_mask = transformed['mask']\n",
    "            elif tile =='t8':\n",
    "                transformed = transform_8(image=img, mask=mask)\n",
    "                transformed_image = transformed['image']\n",
    "                transformed_mask = transformed['mask']\n",
    "\n",
    "            cv2.imwrite('./aug_images/aug_{}_'.format(str(i+1))+file+'.jpg',cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB))\n",
    "            cv2.imwrite('./aug_masks/aug_{}_'.format(str(i+1))+file+'.png',cv2.cvtColor(transformed_mask, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "\u001b[0;32m<ipython-input-10-fae4beb79e15>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0;31m \u001b[0maugment_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-0198ede526ab>\u001b[0m in \u001b[0;36maugment_dataset\u001b[0;34m(count)\u001b[0m\n",
      "\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     20\u001b[0m             \u001b[0mtile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     23\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "augment_dataset(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tzip warning: name not matched: ./aug_images/\n",
      "\n",
      "zip error: Nothing to do! (try: zip -r aug_images.zip . -i ./aug_images/)\n",
      "\tzip warning: name not matched: ./aug_masks/\n",
      "\n",
      "zip error: Nothing to do! (try: zip -r aug_masks.zip . -i ./aug_masks/)\n"
     ]
    }
   ],
   "source": [
    "!zip -r aug_images.zip './aug_images/'\n",
    "!zip -r aug_masks.zip './aug_masks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf './aug_images/'\n",
    "!rm -rf './aug_masks/'"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
